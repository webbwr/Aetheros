= AETHEROS: Architecture and Design Intent Specification
:author: Initial Specification
:revnumber: 0.3.0
:revdate: 2025-01-01
:toc: left
:toclevels: 4
:sectnums:
:sectnumlevels: 4
:icons: font
:source-highlighter: rouge
:experimental:
:stem: latexmath

[abstract]
--
This document defines the architecture and design intent for AETHEROS, a quadripartite microkernel operating system designed from first principles for modern heterogeneous computing platforms. The system prioritizes user experience, mathematical consistency, and conceptual simplicity while embracing structural complexity. All design decisions are guided by the Japanese aesthetic principle of MA (間)—meaningful negative space—ensuring every abstraction earns its existence.

*Target platform:* AMD Ryzen Threadripper PRO 9000 WX-Series with integrated GPU (RDNA) and NPU (XDNA).

*Execution model:* RAM-resident for maximum performance.

*Primary language:* Rust, with strategic use of C/C++ for AMD ecosystem integration and assembly for hardware primitives.

This specification covers: foundational primitives, capability model, four-kernel architecture (Governance, Physical, Emotive, Cognitive), key innovations (capabilities, dataflow, memory domains, typed channels), inter-kernel communication, RAM-resident execution, formal specification approach, language assessment, heterogeneous compute constraints, GPU/NPU DSL design, AI-assisted development model, critical risks, and bootstrap strategy.
--

<<<

== Philosophical Foundations

=== The Problem with Existing Operating Systems

Current operating systems carry accumulated assumptions from decades past:

[cols="1,1",options="header"]
|===
|Legacy Assumption |Modern Reality

|CPU is the compute center
|CPU is the orchestrator; GPU/NPU perform heavy computation

|Memory is scarce; disk is storage
|Memory is abundant; persistent memory blurs boundaries

|Processes are isolated kingdoms
|Fine-grained sharing with strong isolation required

|Sequential by default
|Parallel by default; sequential is the special case

|Files are the universal abstraction
|Typed, structured data demands richer primitives

|Security bolted on (DAC/MAC)
|Security must be architectural (capabilities)

|User adapts to system
|System serves user
|===

AETHEROS rejects these assumptions. It is a fresh start.

=== Guiding Principles

==== MA (間): Meaningful Negative Space

The system is defined as much by what it _excludes_ as what it includes. Every system call, every abstraction, every capability exists because its absence would create a hole. Nothing ornamental. Nothing vestigial.

[quote, Lao Tzu]
____
We shape clay into a pot, but it is the emptiness inside that holds whatever we want.
____

==== Mathematical Consistency

The system is an algebraic object: operations compose, invariants hold, state transitions are total functions. No undefined behavior. No "it depends." The specification _is_ the system; implementation merely instantiates it.

==== Conceptual Simplicity, Structural Complexity

Like a fractal or a fugue: simple generative rules producing rich emergent structure. One model explaining many phenomena. Five primitives. Four kernels. Infinite capability.

==== Full State Awareness

The system always knows what it is. No hidden state. No spooky action at a distance. No "reboot to fix it." State is explicit, observable, and recoverable.

==== User Primacy

The human is not a "user" in the peripheral sense. The human is the _purpose_. Every computational act serves human intention or is explicitly justified by policy. The system is the user's advocate.

<<<

== Architectural Overview

=== The Quadripartite Model

AETHEROS employs four specialized kernels, each with distinct ontological status:

[source]
----
┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│                         GOVERNANCE KERNEL                           │
│                            (Nous/司)                                │
│                                                                     │
│   Policy • Invariants • Arbitration • Oversight                     │
│   "What is permitted? What must always hold?"                       │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
         │                    │                    │
         │ policy             │ policy             │ policy
         ▼                    ▼                    ▼
┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
│                 │  │                 │  │                 │
│    COGNITIVE    │  │    EMOTIVE      │  │    PHYSICAL     │
│     KERNEL      │  │     KERNEL      │  │     KERNEL      │
│    (Logos/理)   │  │   (Thymos/気)   │  │   (Soma/体)     │
│                 │  │                 │  │                 │
│  Reasoning      │  │  User Advocacy  │  │  Actuation      │
│  Planning       │  │  Prioritization │  │  Sensation      │
│  Inference      │  │  Experience QoS │  │  Memory/IO      │
│  Optimization   │  │  Intent Model   │  │  Timing         │
│                 │  │                 │  │                 │
│  "What should   │  │  "What matters  │  │  "What exists   │
│   we do?"       │  │   to the user?" │  │   and happens?" │
│                 │  │                 │  │                 │
│  DELIBERATIVE   │  │  SUBJECTIVE     │  │  REACTIVE       │
│                 │  │                 │  │                 │
└─────────────────┘  └─────────────────┘  └─────────────────┘
----

==== Kernel Responsibilities

[cols="1,2,1,1",options="header"]
|===
|Kernel |Question Answered |Time Horizon |Nature

|*Physical*
|What is? What happened?
|Immediate
|Factual, Reactive

|*Emotive*
|What matters to this user right now?
|Near-term
|Evaluative, Subjective

|*Cognitive*
|What should we do?
|Strategic
|Deliberative, Objective

|*Governance*
|What is permitted? What must hold?
|Eternal
|Normative, Invariant
|===

==== Why Four Kernels?

This pattern recurs across philosophy and systems theory:

[cols="1,1,1,1,1",options="header"]
|===
|Tradition |Physical |Emotive |Cognitive |Governance

|Platonic Soul
|Appetite
|Spirit (Thymos)
|Reason (Logos)
|The Good

|Jungian Functions
|Sensation
|Feeling
|Thinking
|Self

|OODA Loop
|Observe
|Orient
|Decide
|Act (oversight)

|Viable System Model
|Operations
|Coordination
|Control
|Policy
|===

These patterns reflect something true about complex adaptive systems. AETHEROS instantiates this wisdom in silicon.

=== Key Innovations

AETHEROS introduces four fundamental innovations that distinguish it from all existing operating systems:

==== 1. Capabilities, Not Permissions

Every resource reference is an unforgeable token encoding _what you can do_. No ambient authority. No access control lists consulted at runtime. This is how seL4 works—and it is the only security model that composes cleanly.

[source]
----
Traditional Model:
    Process → "Can I access /dev/gpu0?" → Kernel checks ACL → Yes/No

AETHEROS Model:
    Process holds Capability<GPU, ReadWrite> → Access is the capability
    No runtime check needed; possession IS authorization
----

==== 2. Compute as Dataflow, Not Threads

Instead of "spawn thread, manage synchronization," computation is expressed as graphs:

[source]
----
[Sensor Input] → [Preprocess:NPU] → [Inference:GPU] → [Decision:CPU] → [Output]
----

The Cognitive kernel schedules across heterogeneous compute units. This is what AMD attempts with ROCm—but at the wrong abstraction layer. AETHEROS makes it foundational.

==== 3. Memory Domains with Explicit Coherence

Modern heterogeneous systems have _multiple_ memory spaces with different coherence guarantees. AETHEROS exposes this cleanly rather than hiding it:

[cols="1,2",options="header"]
|===
|Domain Type |Semantics

|*CPU-coherent*
|Traditional RAM; hardware maintains coherence

|*Device-local*
|GPU VRAM; not directly CPU-accessible

|*Shared-visible*
|CPU↔GPU shared; explicit synchronization required

|*Persistent*
|Survives power loss (Optane, CXL-attached)
|===

==== 4. Everything is a Typed Channel

Not "everything is a file" (too unstructured) or "everything is an object" (too heavyweight). AETHEROS uses typed, capability-protected channels with schema evolution:

[source,lean]
----
-- Channels are typed; protocol violations are compile errors
def sensorChannel : Channel SensorReading := ...

-- Session types ensure correct sequencing
session GPUJob where
  client sends   : ComputeGraph
  server sends   : Placement
  client sends   : Confirm
  server sends   : JobHandle
  -- ...
----

=== System Layers

The complete AETHEROS architecture forms four distinct layers:

[source]
----
┌────────────────────────────────────────────────────────────────┐
│                      User Space                                │
│    Applications, Services, Shells                              │
│    (Language-agnostic, capability-constrained)                 │
├────────────────────────────────────────────────────────────────┤
│                   Compute Fabric Runtime                       │
│    Unified scheduling across CPU/GPU/NPU                       │
│    Dataflow graphs, not threads                                │
│    Memory: explicit coherence domains, zero-copy channels      │
├────────────────────────────────────────────────────────────────┤
│                    Microkernel Core                            │
│    Four kernels: Governance, Emotive, Cognitive, Physical      │
│    Capabilities, IPC, resource accounting                      │
│    Minimal TCB (~15-20K lines target)                          │
│    Formally verifiable where possible                          │
├────────────────────────────────────────────────────────────────┤
│                   Hardware Abstraction                         │
│    CPU (Zen 5), GPU (RDNA), NPU (XDNA)                         │
│    Unified address space with explicit domains                 │
└────────────────────────────────────────────────────────────────┘
----

<<<

== Foundational Primitives

=== The Five Primitives

Every concept in AETHEROS derives from exactly five primitives:

[cols="1,2,2",options="header"]
|===
|Primitive |Meaning |Mathematical Structure

|*Resource*
|Something that exists and can be used
|Set with equivalence relation

|*Capability*
|Authority to act on a resource
|Morphism in a category

|*Domain*
|Isolated state container
|Object in a category

|*Channel*
|Typed conduit between domains
|Session-typed morphism

|*Transition*
|State change
|Total function on states
|===

Everything else—processes, threads, files, memory, devices—is _derivable_ from these five.

=== Core Equations

[stem]
++++
\text{System} := (\text{Domains}, \text{Channels}, \text{Capabilities}, \text{State}, \text{Transitions})
++++

[stem]
++++
\text{State} := \prod_{d : \text{Domain}} \text{DomainState}(d)
++++

[stem]
++++
\text{Transition} : \text{State} \times \text{Event} \to \text{State}
++++

[stem]
++++
\text{Capability} := (\text{Resource}, \text{Rights}, \text{Provenance})
++++

The invariant preservation property:

[stem]
++++
\forall\, t : \text{Transition},\, \forall\, \text{inv} : \text{Invariant} \implies \text{inv}(\text{state}) \Rightarrow \text{inv}(t(\text{state}, \text{event}))
++++

<<<

== Capability Model

=== Rights Lattice

Capabilities carry rights. Rights form a bounded lattice:

[source,lean]
----
-- The rights a capability can carry
inductive Right where
  | read      -- observe resource state
  | write     -- modify resource state
  | execute   -- invoke resource behavior
  | grant     -- delegate capability to another domain
  | revoke    -- withdraw delegated capabilities
  deriving DecidableEq, Repr

-- Rights form a bounded lattice under set operations
-- ⊤ = all rights, ⊥ = no rights
-- meet = intersection, join = union
----

=== Capability Structure

[source,lean]
----
-- A capability is authority over a resource with specific rights
structure Capability (Resource : Type) where
  resource   : Resource
  rights     : Rights
  provenance : Provenance  -- for revocation tracking
  epoch      : Epoch       -- for temporal validity

-- Capabilities are unforgeable by construction
-- Only Governance kernel can create root capabilities
-- All others derive via delegation
----

=== Fundamental Security Properties

==== No Forgery

[source,lean]
----
theorem no_forgery (s s' : SystemState) (k : Kernel) (c : Capability) :
    c ∈ capabilities k s' →
      c ∈ capabilities k s ∨                    -- already possessed
      (∃ k', Delegated k' k c s s') ∨           -- received via delegation
      (k = .governance ∧ Created c s s')        -- governance created it
----

==== No Amplification

[source,lean]
----
-- Restriction can only reduce rights, never amplify
def restrict (c : Capability R) (mask : Rights) : Capability R :=
  { c with rights := c.rights ∩ mask }

theorem restrict_monotonic (c : Capability R) (m1 m2 : Rights) :
    m1 ⊆ m2 → (restrict c m1).rights ⊆ (restrict c m2).rights
----

==== Revocation Propagation

[source,lean]
----
-- When a capability is revoked, all derivatives are also revoked
theorem revocation_propagation (c : Capability) (s s' : SystemState) :
    Revoked c s s' →
      ∀ c' : Capability, DerivedFrom c' c →
        ¬ Valid c' s'
----

<<<

== Governance Kernel Specification

=== Purpose

The Governance kernel is the _constitutional authority_ of the system. It:

* Holds the root capability from which all others derive
* Defines and enforces system-wide invariants
* Arbitrates conflicts between kernels
* Manages resource budgets across the system
* Maintains audit logs for accountability

=== State Structure

[source,lean]
----
structure GovernanceState where
  capabilityRoot      : Capability Root
  grantedCapabilities : Kernel → List Capability
  activeInvariants    : List Invariant
  resourceBudgets     : Kernel → ResourceBudget
  auditLog            : List AuditEntry
  policyRules         : List PolicyRule
  systemEpoch         : Epoch
----

=== Invariants

[source,tla]
----
\* Governance sovereignty: all capabilities trace to governance
GovernanceSovereignty ==
    ∀ k ∈ Kernels \ {governance} :
        ∀ c ∈ capabilities[k] :
            DerivedFrom(c, governanceState.capabilityRoot)

\* Budget conservation: total grants ≤ total resources
BudgetConservation ==
    ∀ r ∈ Resources :
        Sum(k ∈ Kernels : resourceBudgets[k][r]) ≤ TotalAvailable(r)

\* Audit completeness: all capability changes logged
AuditCompleteness ==
    ∀ c ∈ Capability, k ∈ Kernel :
        (c ∈ capabilities'[k] ∧ c ∉ capabilities[k]) ⇒
            ∃ entry ∈ auditLog' : entry.capability = c ∧ entry.target = k
----

=== Operations

[cols="1,2,1",options="header"]
|===
|Operation |Description |Authority

|`grantCapability`
|Delegate capability to a kernel
|Governance only

|`revokeCapability`
|Withdraw capability from a kernel
|Governance only

|`setResourceBudget`
|Allocate resource quota to kernel
|Governance only

|`enforceInvariant`
|Activate a system invariant
|Governance only

|`arbitrate`
|Resolve inter-kernel conflict
|Governance only

|`queryAudit`
|Read audit log entries
|Any kernel (filtered by capability)
|===

<<<

== Physical Kernel Specification

=== Purpose

The Physical kernel is the _embodiment_ of the system. It:

* Manages all hardware resources directly
* Handles interrupts and exceptions
* Controls memory domains and DMA
* Manages device state
* Provides timing services
* Interfaces with GPU and NPU hardware

=== State Structure

[source,lean]
----
structure PhysicalState where
  -- Memory management
  memoryDomains     : List MemoryDomain
  pageTableRoots    : Domain → PageTableRoot
  dmaBuffers        : List DMABuffer
  
  -- Device management
  deviceStates      : DeviceId → DeviceState
  interruptState    : InterruptController
  pendingInterrupts : Queue Interrupt
  
  -- Timing
  systemTime        : Timestamp
  timerQueues       : List TimerEntry
  
  -- Heterogeneous compute
  gpuState          : GPUState
  npuState          : NPUState
  
  -- Health metrics (reported to Emotive)
  resourceMetrics   : ResourceId → Metrics
----

=== Memory Domain Model

AETHEROS exposes memory heterogeneity explicitly:

[source,lean]
----
inductive MemoryDomainType where
  | cpuCoherent      -- Traditional CPU-coherent RAM
  | deviceLocal      -- GPU VRAM, not CPU-accessible
  | sharedVisible    -- CPU↔GPU shared, explicit sync required
  | persistent       -- Survives power loss (Optane, CXL-PM)
  deriving DecidableEq, Repr

structure MemoryDomain where
  domainType   : MemoryDomainType
  baseAddress  : PhysicalAddress
  size         : Size
  owner        : Domain
  coherence    : CoherenceProtocol
  numaNode     : NUMANode
----

=== Hardware Mapping

[source]
----
Threadripper PRO 9995WX Physical Layout:

┌────────────────────────────────────────────────────────────────────────┐
│                         3TB RAM Address Space                          │
├────────────────────────────────────────────────────────────────────────┤
│                                                                        │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐  │
│  │  Governance  │ │  Cognitive   │ │   Emotive    │ │   Physical   │  │
│  │    Region    │ │    Region    │ │    Region    │ │    Region    │  │
│  │   (NUMA 0)   │ │  (NUMA 1-2)  │ │   (NUMA 3)   │ │   (NUMA 4)   │  │
│  │    ~64MB     │ │   ~512MB     │ │   ~128MB     │ │   ~256MB     │  │
│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘  │
│                                                                        │
│  ┌─────────────────────────────────────────────────────────────────┐  │
│  │                    Shared Channel Region                         │  │
│  │            (explicitly coherent, message buffers)                │  │
│  │                         ~256MB                                   │  │
│  └─────────────────────────────────────────────────────────────────┘  │
│                                                                        │
│  ┌─────────────────────────────────────────────────────────────────┐  │
│  │                    Application Space                             │  │
│  │              (capability-partitioned domains)                    │  │
│  │                    ~2.99TB remaining                             │  │
│  └─────────────────────────────────────────────────────────────────┘  │
│                                                                        │
└────────────────────────────────────────────────────────────────────────┘

CPU Core Assignment (96 cores):
├── Governance:   4 cores (dedicated, highest priority)
├── Cognitive:   24 cores (deliberative computation, GPU/NPU control)
├── Emotive:      8 cores (monitoring, intent inference)
├── Physical:    16 cores (I/O, interrupts, device management)
└── Application: 44 cores (user workloads, dynamically scheduled)
----

=== Operations

[cols="1,2,1",options="header"]
|===
|Operation |Description |Authority

|`allocateMemory`
|Create memory region in specified domain type
|Physical (authorized by Governance)

|`mapMemory`
|Establish virtual→physical mapping
|Physical

|`initiateTransfer`
|Begin DMA or device I/O
|Physical

|`registerInterrupt`
|Establish interrupt handler
|Physical

|`queryTime`
|Read system timestamp
|Any kernel

|`setTimer`
|Schedule timer callback
|Any kernel

|`submitGPU`
|Enqueue GPU work
|Physical (on behalf of Cognitive)

|`submitNPU`
|Enqueue NPU inference
|Physical (on behalf of Cognitive)
|===

<<<

== Emotive Kernel Specification

=== Purpose

The Emotive kernel is the _user's advocate_. It:

* Infers user intent from signals
* Monitors experience quality
* Computes priorities for system behavior
* Tracks system health from user's perspective
* Ensures the system serves human needs

This is the only kernel that reasons about _subjective experience_.

=== The Core Question

The Emotive kernel continuously answers:

[quote]
____
"Is this system serving this human well, right now?"
____

=== State Structure

[source,lean]
----
structure EmotiveState where
  -- Temporal awareness
  currentMoment     : Moment
  
  -- User modeling
  intentModel       : IntentModel
  userPresence      : PresenceState
  userProfile       : UserProfile
  
  -- Experience tracking
  experienceHistory : RingBuffer (Moment × ExperienceQuality)
  currentExperience : ExperienceQuality
  
  -- System health (from user's perspective)
  healthSnapshot    : SystemHealth
  
  -- Output
  currentPriority   : Priority
----

=== Intent Model

[source,lean]
----
-- User intent as probability distribution over goals
structure IntentModel where
  goals         : List Goal
  probabilities : Goal → Probability
  confidence    : Confidence
  lastUpdated   : Moment

-- A goal is something the user might be trying to achieve
structure Goal where
  description  : GoalDescriptor
  deadline     : Option Deadline
  importance   : Importance
  dependencies : List ResourceNeed

-- Intent inference via Bayesian update
def updateIntent (current : IntentModel) (signal : Signal) : IntentModel :=
  let newProbs := fun goal =>
    let prior := current.probabilities goal
    let likelihood := signalLikelihood signal goal
    let evidence := Σ g, current.probabilities g * signalLikelihood signal g
    (prior * likelihood) / evidence  -- Bayes' rule
  { current with 
    probabilities := newProbs
    lastUpdated := now
    confidence := computeConfidence newProbs }
----

=== User Presence Model

[source,lean]
----
-- The user's engagement state
inductive PresenceState where
  | activeFocus    (since : Moment) (intensity : Intensity)
  | passiveAttention (since : Moment)
  | background     (since : Moment) (expectedReturn : Option Moment)
  | absent         (since : Moment)
  deriving Repr

-- Presence affects system behavior
def presenceBehavior : PresenceState → SystemBehavior
  | .activeFocus _ _    => .maximizeResponsiveness
  | .passiveAttention _ => .balanceQualityEfficiency
  | .background _ _     => .optimizeThroughput
  | .absent _           => .maintenanceMode
----

=== Experience Quality Model

[source,lean]
----
-- Multi-dimensional experience quality measure
structure ExperienceQuality where
  responsiveness : Ratio  -- perceived latency vs expected
  accuracy       : Ratio  -- output correctness
  coherence      : Ratio  -- consistency of experience
  aesthetics     : Ratio  -- subjective quality
  overall        : Ratio  -- weighted combination

-- Quality computation varies by presence
def computeOverallExperience (eq : ExperienceQuality) 
                              (presence : PresenceState) : Ratio :=
  match presence with
  | .activeFocus _ _ => 
      0.50 * eq.responsiveness + 
      0.20 * eq.accuracy + 
      0.20 * eq.coherence + 
      0.10 * eq.aesthetics
  | .passiveAttention _ => 
      0.30 * eq.responsiveness + 
      0.30 * eq.accuracy + 
      0.20 * eq.coherence + 
      0.20 * eq.aesthetics
  | _ => 
      0.20 * eq.responsiveness + 
      0.40 * eq.accuracy + 
      0.30 * eq.coherence + 
      0.10 * eq.aesthetics
----

=== Priority Output

[source,lean]
----
-- The Emotive kernel's output to other kernels
structure Priority where
  focus         : Goal           -- primary goal to serve
  urgency       : Urgency        -- time criticality
  resourceBudget: ResourceBudget -- allocation guidance
  qualityTarget : ExperienceQuality  -- minimum acceptable

-- Directives to specific kernels
structure CognitiveDirective where
  primaryGoal    : Goal
  secondaryGoals : List Goal
  deadline       : Option Deadline
  qualityFloor   : ExperienceQuality

structure PhysicalDirective where
  latencyBudget  : Duration
  allocation     : ResourceBudget
  powerMode      : PowerMode
  preemptPriority: Priority
----

=== Input Signal Sources

[source]
----
Intent Signal Sources:

  Explicit                    Implicit
  ────────                    ────────
  • Commands issued           • Input patterns (mouse, keyboard)
  • Applications launched     • Window focus duration
  • Files opened              • Scroll behavior
  • Queries made              • Pause patterns
                              • Time of day / context
                              • Historical patterns

  Physiological (optional)
  ────────────────────────
  • Eye tracking              • Heart rate variability
  • Facial expression         • Skin conductance
----

=== Invariants

[source,tla]
----
\* Priority always reflects current state
PriorityFreshness ==
    currentPriority = ComputePriority(intentModel, experienceQuality,
                                      systemHealth, userPresence)

\* Active user implies elevated urgency
PresenceAffectsUrgency ==
    userPresence = ActiveFocus ⇒ currentPriority.urgency ≥ BaselineUrgency

\* Experience degradation triggers response
ResponsiveToDegradation ==
    experienceQuality.overall < AcceptableThreshold ↝
        currentPriority.urgency > HighUrgency ∨ DegradationStrategyActive
----

<<<

== Cognitive Kernel Specification

=== Purpose

The Cognitive kernel is the _reasoning engine_. It:

* Plans and schedules computations
* Manages GPU and NPU workloads
* Optimizes resource utilization
* Executes inference and deliberation
* Responds to Emotive kernel priorities

=== State Structure

[source,lean]
----
structure CognitiveState where
  -- Active computation
  activeComputations : List ComputeGraph
  pendingDecisions   : Queue Decision
  
  -- Resource tracking
  gpuWorkQueue       : Queue GPUWork
  npuWorkQueue       : Queue NPUWork
  cpuTaskQueue       : PriorityQueue Task
  
  -- Models and caches
  worldModel         : WorldModel
  planCache          : PlanId → Plan
  
  -- Optimization state
  schedulerState     : SchedulerState
  placementPolicy    : PlacementPolicy
----

=== Compute Graph Model

AETHEROS models computation as dataflow graphs, not threads:

[source,lean]
----
-- A compute graph expresses data dependencies
structure ComputeGraph where
  nodes : List ComputeNode
  edges : List DataEdge
  constraints : List SchedulingConstraint

-- Nodes can target different compute units
inductive ComputeTarget where
  | cpu (cores : CoreSet)
  | gpu (workgroups : Nat)
  | npu (tiles : Nat)
  | any  -- scheduler decides

structure ComputeNode where
  id         : NodeId
  operation  : Operation
  target     : ComputeTarget
  inputs     : List DataPort
  outputs    : List DataPort
  deadline   : Option Deadline
----

=== Heterogeneous Scheduling

[source,lean]
----
-- Placement decisions consider:
-- 1. Data locality (minimize transfers)
-- 2. Compute affinity (match operation to accelerator)
-- 3. Deadline feasibility
-- 4. Energy efficiency
-- 5. Current load

structure PlacementDecision where
  node   : ComputeNode
  target : ComputeTarget
  reason : PlacementReason

def computePlacement (graph : ComputeGraph) 
                      (health : SystemHealth)
                      (priority : Priority) : List PlacementDecision :=
  -- Multi-objective optimization
  -- Priority from Emotive kernel influences weights
  sorry
----

=== Operations

[cols="1,2,1",options="header"]
|===
|Operation |Description |Authority

|`submitGraph`
|Schedule a compute graph for execution
|Cognitive

|`queryPlan`
|Retrieve or generate execution plan
|Cognitive

|`cancelComputation`
|Abort in-progress computation
|Cognitive (authorized by Emotive)

|`adjustPriority`
|Modify task priority
|Cognitive (guided by Emotive)

|`reportCompletion`
|Signal computation finished
|Cognitive → Emotive
|===

<<<

== Inter-Kernel Communication

=== Channel Model

Kernels communicate via typed, capability-protected channels. There is *no shared mutable state* between kernels.

[source]
----
Inter-Kernel Channel Topology:

                    Governance
                    ┌───┴───┐
            policy──┤       ├──policy
                    │       │
        ┌───────────┘       └───────────┐
        │                               │
        ▼                               ▼
   Cognitive ◄─────request/────────► Emotive
        │         response              │
        │                               │
        │         ┌───────┐             │
        └────────►│Physical│◄───────────┘
                  └───────┘
            sense/actuate  sense/actuate
----

=== Channel Type Definitions

[source,lean]
----
-- Physical → Emotive: Sensory events with salience
inductive PhysicalToEmotive where
  | sensorEvent (sensor : SensorId) (value : SensorValue) (ts : Timestamp)
  | resourcePressure (resource : ResourceId) (pressure : Ratio)
  | faultDetected (fault : FaultDescriptor)
  | ioCompleted (request : IORequestId) (result : IOResult)
  | healthMetrics (metrics : SystemMetrics)

-- Emotive → Cognitive: Prioritized attention
inductive EmotiveToCognitive where
  | directive (d : CognitiveDirective)
  | attendTo (focus : Goal) (urgency : Urgency)
  | deprioritize (target : Goal)
  | deadlineApproaching (goal : Goal) (remaining : Duration)

-- Cognitive → Physical: Action commands
inductive CognitiveToPhysical where
  | scheduleCompute (graph : ComputeGraph) (placement : Placement)
  | allocateMemory (domain : MemoryDomain) (size : Size)
  | initiateIO (device : DeviceId) (op : IOOperation)
  | setTimers (timers : List TimerRequest)

-- Governance → All: Policy directives
inductive GovernanceDirective where
  | grantCapability (target : Kernel) (cap : Capability)
  | revokeCapability (target : Kernel) (cap : Capability)
  | setResourceBudget (target : Kernel) (budget : ResourceBudget)
  | enforceInvariant (inv : Invariant)
  | requestAudit (scope : AuditScope)
----

=== Synchronization Model

[source,lean]
----
-- Communication modes
inductive ChannelMode where
  | async      -- Non-blocking send, buffered
  | rendezvous -- Synchronous handshake
  | priority   -- Preemptive (governance only)

-- Channel operations are capability-protected
structure ChannelOp (M : Type) where
  channel    : ChannelId
  capability : Capability Channel
  mode       : ChannelMode
  message    : M
----

=== Deadlock Freedom

The channel topology is acyclic by construction:

[source,tla]
----
\* Channel dependencies form a DAG
ChannelDAG ==
    LET deps == {<<k1, k2>> : k1, k2 ∈ Kernels : CanSendTo(k1, k2)}
    IN  IsDAG(deps)

\* Governance can always intervene (breaks potential cycles)
GovernanceIntervention ==
    ∀ k ∈ Kernels \ {governance} :
        □◇ (CanReceiveFrom(k, governance))
----

<<<

== RAM-Resident Execution Model

=== Rationale

AETHEROS executes entirely in RAM for:

* *Deterministic latency* — No disk I/O in critical paths
* *Simplified state model* — Memory is the canonical state
* *Performance* — DDR5 bandwidth (~460 GB/s) exceeds all storage
* *Integrity* — State is always consistent (no partial writes)

=== State Persistence

RAM is volatile. AETHEROS employs checkpoint-based persistence:

[source,lean]
----
structure CheckpointPolicy where
  interval      : Duration        -- Time between checkpoints
  trigger       : CheckpointTrigger  -- Additional triggers
  storage       : StorageTarget   -- NVMe, network, etc.
  compression   : CompressionAlgo
  verification  : VerificationMode

inductive CheckpointTrigger where
  | periodic (interval : Duration)
  | stateChange (threshold : ChangeVolume)
  | userRequest
  | lowPower
  | preShutdown

-- Checkpoint contains all kernel states
structure Checkpoint where
  epoch         : Epoch
  timestamp     : Timestamp
  governance    : GovernanceState
  physical      : PhysicalState
  emotive       : EmotiveState
  cognitive     : CognitiveState
  channels      : ChannelState
  hash          : CryptoHash
----

=== Recovery Model

[source,lean]
----
-- Recovery reconstructs system from checkpoint + journal
def recover (checkpoint : Checkpoint) 
            (journal : List JournalEntry) : SystemState :=
  let base := reconstructFromCheckpoint checkpoint
  let final := journal.foldl applyJournalEntry base
  verify final
  final

-- Recovery is a total function — always succeeds or fails cleanly
theorem recovery_totality (c : Checkpoint) (j : List JournalEntry) :
    Valid c → ValidJournal j c.epoch →
      ∃ s : SystemState, recover c j = s ∧ Consistent s
----

<<<

== Formal Specification Languages

=== Specification Stack

AETHEROS uses a layered formal approach:

[cols="1,1,2",options="header"]
|===
|Layer |Tool |Purpose

|Behavioral semantics
|*TLA+*
|Concurrent state transitions, temporal properties, model checking

|Structural foundations
|*Lean 4*
|Type theory, capability algebra, theorem proving, code extraction

|Interface contracts
|*Session types*
|Protocol correctness between components
|===

=== TLA+ Module Structure

[source,tla]
----
------------------------ MODULE AETHEROS ------------------------
EXTENDS Naturals, Sequences, FiniteSets, TLC

CONSTANTS
    Resources, Rights, Kernels, Domains

VARIABLES
    physicalState, emotiveState, cognitiveState, governanceState,
    channels, capabilities, systemEpoch

vars == <<physicalState, emotiveState, cognitiveState, 
          governanceState, channels, capabilities, systemEpoch>>

------------------------------------------------------------------
\* TYPE INVARIANTS
------------------------------------------------------------------
TypeInvariant ==
    /\ physicalState ∈ PhysicalStateSpace
    /\ emotiveState ∈ EmotiveStateSpace
    /\ cognitiveState ∈ CognitiveStateSpace
    /\ governanceState ∈ GovernanceStateSpace
    /\ channels ∈ ChannelStateSpace
    /\ capabilities ∈ [Kernels → SUBSET Capability]

------------------------------------------------------------------
\* SAFETY INVARIANTS
------------------------------------------------------------------
NoForgery == ...
GovernanceSovereignty == ...
BudgetConservation == ...
KernelIsolation == ...

------------------------------------------------------------------
\* LIVENESS PROPERTIES
------------------------------------------------------------------
UserResponsiveness == ...
DeadlockFreedom == ...
FairnessGuarantees == ...

==================================================================
----

=== Lean 4 Module Structure

[source,lean]
----
-- AETHEROS.Foundations: Core mathematical structures
-- AETHEROS.Capability: Capability algebra and proofs
-- AETHEROS.Resource: Resource model
-- AETHEROS.Channel: Session-typed communication
-- AETHEROS.Kernel.Governance: Governance kernel spec
-- AETHEROS.Kernel.Physical: Physical kernel spec
-- AETHEROS.Kernel.Emotive: Emotive kernel spec
-- AETHEROS.Kernel.Cognitive: Cognitive kernel spec
-- AETHEROS.System: Composed system and invariants
----

<<<

== User Primacy Invariant

=== The Supreme Invariant

The deepest invariant of AETHEROS:

[source,lean]
----
-- Every system decision either serves the user's priority
-- or is explicitly overridden by governance for policy reasons
theorem user_primacy (s : SystemState) :
    ∀ decision : SystemDecision,
      MadeBy decision s.cognitive ∨ MadeBy decision s.physical →
        ConsistentWith decision (s.emotive.currentPriority) ∨
        OverriddenBy decision s.governance
----

In plain language: *Nothing happens in this system that isn't either serving the user or explicitly justified by policy.*

=== Implications

[cols="1,2",options="header"]
|===
|Principle |Implementation

|*No hidden computation*
|All background work is budgeted and accountable

|*No surprise latency*
|Emotive kernel sets latency expectations; violations are reported

|*No silent failures*
|All faults surface to user-visible experience metrics

|*No unauthorized resource use*
|Governance budgets bound all kernel resource consumption

|*No forgotten requests*
|Intent model tracks all user goals until completion or explicit abandonment
|===

<<<

== Implementation Language

=== Primary Language: Rust

AETHEROS is implemented primarily in Rust for:

* *Memory safety without runtime cost* — No GC, no buffer overflows
* *Data race prevention* — Compile-time ownership prevents races
* *Algebraic types* — Capabilities as types; invalid states unrepresentable
* *No legacy compromise* — `#![no_std]` designed for OS development
* *Async primitives* — Futures compose; maps to dataflow model
* *Developer attraction* — Modern systems programmers gravitate to Rust

=== Supporting Languages

[cols="1,1,2",options="header"]
|===
|Component |Language |Rationale

|Boot, context switch
|x86-64 assembly
|Unavoidable (~2% of codebase)

|GPU compute kernels
|Custom DSL → SPIR-V
|Functional data-parallel; schedule separation

|System configuration
|Nix-like declarative
|Reproducibility, declarative specification

|Shell/scripting
|Rust-native (Nushell-like)
|Typed pipelines, seamless integration
|===

=== Capability Encoding in Rust

[source,rust]
----
// Capabilities as types — invalid states unrepresentable
pub struct Capability<R: Resource, const RIGHTS: Rights> {
    resource: R,
    provenance: Provenance,
    epoch: Epoch,
    _phantom: PhantomData<Rights>,
}

// Type-level rights prevent capability amplification
impl<R: Resource, const RIGHTS: Rights> Capability<R, RIGHTS> {
    // Can only restrict, never amplify
    pub fn restrict<const NEW_RIGHTS: Rights>(self) -> Capability<R, NEW_RIGHTS>
    where
        NEW_RIGHTS: Subset<RIGHTS>,
    {
        Capability {
            resource: self.resource,
            provenance: self.provenance,
            epoch: self.epoch,
            _phantom: PhantomData,
        }
    }
}
----

<<<

== Language Assessment: Detailed Analysis

=== The Critical Tension

Soft real-time demands predictability—bounded worst-case execution time (WCET) within statistical tolerances. This creates friction with some otherwise attractive language choices.

=== Language Comparison Matrix

[cols="1,1,1,1,1",options="header"]
|===
|Criterion |C |Rust |Ada/SPARK |Assessment

|*WCET Analyzability*
|Mature tooling (aiT, RapiTime, OTAWA)
|Tooling nascent; bounds checking has timing implications
|Decades of aerospace/defense deployment
|C and Ada lead

|*Memory Safety*
|Manual, error-prone
|Compile-time guarantees
|Strong typing, SPARK subset provable
|Rust and SPARK lead

|*Certification Paths*
|DO-178C, IEC 61508, ISO 26262 established
|Ferrocene exists but ecosystem thin
|Mature certification ecosystem
|C and Ada lead

|*Timing Transparency*
|No hidden costs
|Bounds checking, panic handling have costs
|Ravenscar profile is deterministic
|C and Ada lead

|*Concurrency Safety*
|Manual, race-prone
|Compile-time data race prevention
|Protected objects, rendezvous
|Rust leads for correctness

|*Developer Ecosystem*
|Massive, aging
|Growing, enthusiastic
|Niche, specialized
|C leads in size; Rust in momentum

|*AMD Driver Compatibility*
|Native (ROCm is C/C++)
|FFI required
|FFI required
|C leads
|===

=== C: The Incumbent Standard

Why C dominates RTOS today (QNX, VxWorks, RTEMS, Zephyr):

* *WCET analyzability* — mature tooling with decades of refinement
* *Certifiable* — established paths for safety-critical standards
* *No hidden costs* — what you write is what executes
* *Timing transparency* — no GC pauses, no implicit allocations

For a 96-core NUMA topology, C permits precise reasoning about cache behavior, memory placement, and scheduling.

*Weakness:* Memory safety requires heroic discipline. Buffer overflows, use-after-free, and data races are endemic.

=== Rust: The Modern Contender

Friction points for hard real-time:

[cols="1,2",options="header"]
|===
|Concern |Issue

|WCET analysis
|Tooling nascent; bounds checking has timing implications

|Certification
|Ferrocene exists but ecosystem thin

|`async`/`await`
|Non-deterministic timing characteristics

|Panic handling
|Runtime implications in `no_std` contexts
|===

*Strength:* Compile-time memory safety and data race prevention. For a 96-core system, this is transformative.

Rust _can_ work for real-time—see Oxide Computer's Hubris—but you build tooling alongside the kernel.

=== Ada/SPARK: The Underappreciated Option

Genuinely worth considering:

* *Ravenscar profile* — deterministic tasking model designed for real-time
* *SPARK subset* — formally provable, eliminates entire bug classes mathematically
* *Mature WCET analysis* — decades of aerospace/defense deployment
* *Native concurrency semantics* — protected objects, rendezvous

*Weakness:* AMD driver ecosystem is C-centric. FFI boundaries add complexity.

=== AETHEROS Language Strategy

Given soft real-time requirements and the priority on safety and modern design:

[source]
----
┌─────────────────────────────────────────────────────────────────┐
│  Timing-Critical Core (if hard real-time needed)               │
│  ───────────────────────────────────────────────                │
│  C (scheduler hot paths) + Ada/SPARK (safety-critical)         │
│  Assembly (interrupt handlers, context switch)                  │
├─────────────────────────────────────────────────────────────────┤
│  Primary System Implementation                                  │
│  ─────────────────────────────                                  │
│  Rust (kernels, IPC, memory management, drivers)               │
│  Compile-time safety justifies minor timing overhead            │
├─────────────────────────────────────────────────────────────────┤
│  Heterogeneous Compute Integration                              │
│  ─────────────────────────────────                              │
│  C++ (ROCm/HIP integration, existing AMD tooling)              │
│  Custom DSL (GPU/NPU compute kernels)                          │
└─────────────────────────────────────────────────────────────────┘
----

For AETHEROS specifically—soft real-time, user-focused, greenfield—*Rust is the primary choice* with strategic use of C/C++ for AMD ecosystem integration.

<<<

== The Heterogeneous Compute Problem

=== GPUs Are Fundamentally Non-Deterministic

This is a hard truth that constrains the design. AMD's RDNA/CDNA architectures exhibit:

[cols="1,2",options="header"]
|===
|Characteristic |Timing Implication

|*Variable warp scheduling*
|Execution order within a workgroup is non-deterministic

|*Memory coalescing timing variance*
|Memory access patterns affect latency unpredictably

|*Driver-level preemption*
|GPU context switches are not precisely timed

|*Thermal throttling*
|Performance varies with temperature state

|*Resource contention*
|Multiple kernels sharing GPU creates interference
|===

=== Implications for Soft Real-Time

For AETHEROS's soft real-time model, GPU/NPU workloads must be handled carefully:

[cols="1,2",options="header"]
|===
|Strategy |Description

|*Isolation to non-critical paths*
|GPU work never blocks user-facing latency-critical operations

|*Conservative WCET padding*
|Budget 2-3x typical execution time for deadline calculations

|*Soft real-time subsystem*
|GPU scheduled with statistical guarantees, not hard deadlines

|*Preemption points*
|Design compute graphs with known-duration segments

|*Fallback paths*
|CPU can complete work if GPU misses soft deadline
|===

=== The NPU Difference

AMD's XDNA architecture is more predictable than the GPU:

* *Fixed-function tiles* — Less scheduling variance
* *DMA-based data movement* — More predictable transfer times
* *Inference workloads* — Typically consistent iteration counts

The Emotive kernel may leverage NPU for pattern recognition (user intent inference) with tighter timing bounds than GPU-based approaches.

<<<

== The GPU/NPU Language Problem

=== Current Options Are Inadequate

[cols="1,2,1",options="header"]
|===
|Option |Description |Limitation

|*CUDA/HIP*
|Imperative, C++-like GPU programming
|Low-level, non-portable, AMD-specific (HIP)

|*OpenCL*
|Portable heterogeneous compute
|Effectively abandoned, verbose

|*WGSL*
|WebGPU shading language
|Web-constrained, limited compute focus

|*MLIR/LLVM*
|Compiler infrastructure for accelerators
|Right abstraction layer, wrong ergonomics for users

|*Triton*
|Python-based GPU kernel language
|Python dependency, JIT overhead
|===

=== The AETHEROS Approach: Algorithm/Schedule Separation

Inspired by Halide's key insight: *separate what to compute from how to compute it*.

[source]
----
Traditional Approach:
┌─────────────────────────────────────────┐
│  Algorithm + Schedule + Target          │
│  (all intertwined in CUDA/HIP code)     │
└─────────────────────────────────────────┘

AETHEROS Approach:
┌─────────────────────────────────────────┐
│  Algorithm (pure, functional)           │
│  "What to compute"                      │
├─────────────────────────────────────────┤
│  Schedule (optimization strategy)       │
│  "How to parallelize, tile, fuse"       │
├─────────────────────────────────────────┤
│  Target (hardware binding)              │
│  "CPU / GPU / NPU"                      │
└─────────────────────────────────────────┘
----

=== Proposed DSL Characteristics

[source,lean]
----
-- Functional, data-parallel core
-- No side effects in compute expressions
-- Explicit data dependencies

-- Example: Matrix multiply expressed functionally
def matmul (A : Tensor [M, K]) (B : Tensor [K, N]) : Tensor [M, N] :=
  Tensor.generate (M, N) fun (i, j) =>
    Σ k : Fin K, A[i, k] * B[k, j]

-- Schedule is separate
schedule matmul with
  | tile (i, j) by (32, 32)
  | parallelize i
  | vectorize j
  | target GPU.workgroup

-- Compiles to:
-- • SPIR-V (portable)
-- • GCN/RDNA ISA (AMD native)
-- • XDNA binary (NPU)
----

=== Compilation Targets

[cols="1,2,1",options="header"]
|===
|Target |Format |Use Case

|*Portable*
|SPIR-V
|Cross-vendor GPU compute

|*AMD GPU Native*
|GCN/RDNA ISA
|Maximum performance on target hardware

|*AMD NPU*
|XDNA binary
|Neural network inference acceleration

|*CPU Fallback*
|Native (via LLVM)
|Development, debugging, compatibility
|===

=== This May Need to Be Invented

The DSL described above does not fully exist. Components exist:

* *Halide* — algorithm/schedule separation for image processing
* *Futhark* — functional data-parallel language
* *Regent* — implicit parallelism via Legion
* *Triton* — Python-embedded GPU DSL

AETHEROS may need to synthesize these ideas into a coherent, Rust-integrated DSL. This is potentially the project's most novel contribution.

<<<

== Critical Risks and Mitigations

=== Risk Assessment Matrix

[cols="1,1,2,2",options="header"]
|===
|Risk |Severity |Description |Mitigation

|*Driver Ecosystem*
|Critical
|AMD's stack (ROCm, AMDGPU) assumes Linux. Porting or replacing is massive.
|Phase approach: run on Linux first via virtualization; native drivers later. Consider Mesa/Gallium3D as intermediate layer.

|*Application Ecosystem*
|Critical
|An OS without software is a curiosity.
|WASM as portable application format from day one. Linux syscall compatibility layer for bootstrap.

|*Scope Creep*
|High
|"Superior to all existing OSes" is seductive and dangerous.
|Define _specific_ superiorities. Ruthlessly cut scope. MA principle: what can we remove?

|*Formal Verification Complexity*
|High
|Full verification of four kernels is multi-decade effort.
|Verify critical invariants only. Use Lean 4 for specification; prove key theorems. Accept partial verification.

|*Heterogeneous Scheduling*
|Medium
|Optimal placement across CPU/GPU/NPU is research-grade problem.
|Start with heuristics. Integrate Legion/Realm insights. Iterate based on real workloads.

|*Team/Resource*
|Variable
|Solo effort vs. funded team changes everything.
|Define minimum viable kernel. Build community early. Open source from day one.

|*Hardware Evolution*
|Medium
|AMD architectures will change.
|Abstract hardware behind clean interfaces. Design for portability within AMD ecosystem.
|===

=== The Honest Assessment

[quote]
____
This is a decade-scale undertaking for a well-resourced team, or a lifetime project for a smaller effort.
____

[cols="1,2",options="header"]
|===
|Scenario |Timeline

|*Well-funded team (10-20 engineers)*
|5-7 years to production-ready system

|*Small team (3-5 engineers)*
|10-15 years to production-ready system

|*Solo/hobby effort*
|Lifetime project; focus on specific innovations

|*Research context*
|3-5 years to publishable prototype demonstrating key ideas
|===

The path chosen should match available resources. A focused prototype demonstrating the quadripartite model and capability system has value even if full production is not achieved.

<<<

== Bootstrap Strategy

=== First Steps: Concrete Actions

[cols="1,3,1",options="header"]
|===
|Step |Description |Deliverable

|*1. Architectural Manifesto*
|Define invariants. What will AETHEROS _never_ compromise? What are the non-negotiable principles?
|This document (v1.0)

|*2. Capability Prototype*
|Implement capability model in Rust, running in Linux userspace. Validate IPC semantics.
|Working Rust crate with tests

|*3. Heterogeneous Scheduler Prototype*
|Build dataflow scheduler targeting CPU+GPU, running on Linux. Use existing ROCm.
|Benchmark suite, scheduler implementation

|*4. GPU DSL Design*
|Specify the compute DSL. Implement minimal compiler to SPIR-V.
|Language specification, prototype compiler

|*5. Minimal Microkernel*
|Boot on QEMU. Implement Governance + Physical kernels. Capability-based IPC.
|Bootable image, passing test suite

|*6. Emotive Kernel Prototype*
|Implement intent inference and priority computation. Initially as Linux daemon for iteration.
|Working prototype with metrics

|*7. Bare Metal Boot*
|Boot on real Threadripper PRO hardware. Basic device initialization.
|Hardware validation

|*8. Driver Development*
|Native GPU driver (RDNA). This is the hard part.
|Working graphics/compute
|===

=== Prototype-First Philosophy

[source]
----
                    ┌─────────────────────────┐
                    │  Production AETHEROS    │
                    │  (Years away)           │
                    └───────────┬─────────────┘
                                │
              ┌─────────────────┼─────────────────┐
              │                 │                 │
              ▼                 ▼                 ▼
     ┌────────────────┐ ┌────────────────┐ ┌────────────────┐
     │ Capability     │ │ Scheduler      │ │ Emotive        │
     │ Prototype      │ │ Prototype      │ │ Prototype      │
     │ (Linux user)   │ │ (Linux+ROCm)   │ │ (Linux daemon) │
     └────────────────┘ └────────────────┘ └────────────────┘
              │                 │                 │
              └─────────────────┼─────────────────┘
                                │
                                ▼
                    ┌─────────────────────────┐
                    │  Validate ideas on      │
                    │  existing platform      │
                    │  before committing to   │
                    │  bare metal             │
                    └─────────────────────────┘
----

Each component can be prototyped on Linux, validated, and refined _before_ the massive investment of bare-metal implementation. This de-risks the architecture.

=== What Success Looks Like (Staged)

*Year 1:*

* Formal specification complete (TLA+, Lean 4)
* Capability prototype validated
* Scheduler prototype showing heterogeneous placement

*Year 2-3:*

* Minimal microkernel booting on QEMU
* Four kernels communicating via typed channels
* GPU DSL producing working SPIR-V

*Year 3-5:*

* Bare metal boot on target hardware
* Basic GPU acceleration working
* First applications running

*Year 5+:*

* Driver ecosystem expanding
* Application ecosystem developing
* Community growth

<<<

== AI-Assisted Development Model

=== The Role of Claude Code

AETHEROS development can leverage AI assistance through Claude Code as a collaborative tool. This section honestly assesses capabilities and limitations.

=== What Claude Code Can Do Well

[cols="1,2",options="header"]
|===
|Capability |Assessment

|*Generate Rust/Assembly*
|Strong, with human review required

|*Maintain Architectural Consistency*
|Good within context window (~200K tokens); requires external documentation for continuity

|*Implement Known Algorithms*
|Strong—scheduling, memory management, IPC patterns well-understood

|*Translate Formal Specs to Code*
|Reasonable if specifications are precise

|*Iterate on Feedback*
|Excellent; tireless and egoless

|*Explain and Document*
|Very strong

|*Refactor and Simplify*
|Good—can apply MA principles to code systematically

|*Generate TLA+/Lean 4 Specifications*
|Moderate to strong; requires verification by tools
|===

=== What Claude Code Cannot Do

[cols="1,2",options="header"]
|===
|Limitation |Implication

|*No Persistent State*
|Human must maintain architectural memory across sessions

|*Cannot Test on Hardware*
|Physical validation loops require human intervention

|*Cannot Execute the OS*
|Debugging requires human observation on real/emulated hardware

|*Context Window Bounds*
|Cannot hold entire OS in "mind" simultaneously

|*No Genuine Invention*
|Synthesizes brilliantly; true origination is uncertain

|*Subtle Errors Possible*
|Especially in low-level code, interrupt handling, memory ordering

|*No Accountability*
|Cannot own correctness; human must verify all output
|===

=== The Collaboration Topology

[source]
----
┌─────────────────────────────────────────────────────────────┐
│                        HUMAN                                │
│   ─────────────────────────────────────────                 │
│   • Architectural authority                                 │
│   • Mathematical foundations (type theory, invariants)      │
│   • Hardware validation                                     │
│   • Final correctness responsibility                        │
│   • Long-term memory of the system                          │
├─────────────────────────────────────────────────────────────┤
│                    CLAUDE CODE                              │
│   ─────────────────────────────────────────                 │
│   • Implementation at human direction                       │
│   • Translation of specs to code                            │
│   • Refactoring toward simplicity                           │
│   • Documentation and explanation                           │
│   • Alternative exploration ("show me three approaches")    │
│   • Tedious but important work (test generation, etc.)      │
├─────────────────────────────────────────────────────────────┤
│                  FORMAL TOOLS                               │
│   ─────────────────────────────────────────                 │
│   • Proof assistants (Lean 4, Coq, Isabelle)                │
│   • Model checkers (TLA+, SPIN)                             │
│   • The arbiter of mathematical truth                       │
└─────────────────────────────────────────────────────────────┘
----

=== Critical Understanding

[quote]
____
Claude Code can _write_ TLA+ specs, _generate_ Lean proofs, _produce_ Rust implementations. But the proof assistant is the authority, not Claude's assertion.
____

Claude Code has never built a production OS. Neither has any other LLM. This means:

* No learned intuition about what _actually_ goes wrong at 3 AM
* No embodied experience of debugging a triple fault
* No accumulated wisdom about what seems elegant but fails at scale

Claude can synthesize the _knowledge_ of OS builders. That is not the same as _being_ one.

=== Recommended Workflow

1. *Human defines mathematical intent*—What should be true? What are the invariants?

2. *Claude drafts formal specifications*—Lean 4 definitions, TLA+ modules, proofs

3. *Human verifies with tools*—Run Lean's type checker, TLC model checker

4. *Iterate*—Refine until specification is tight, minimal, proven

5. *Claude generates implementation*—Rust code derived from verified specs

6. *Human validates on hardware*—The final arbiter of correctness

=== Force Multiplier Estimate

With Claude Code as a capable assistant, development effort may compress:

[cols="1,1,1",options="header"]
|===
|Phase |Without AI |With AI Assistance

|Specification writing
|1x
|0.3-0.5x (significant speedup)

|Implementation
|1x
|0.5-0.7x (moderate speedup)

|Debugging
|1x
|0.8-1.0x (limited help)

|Hardware integration
|1x
|0.9-1.0x (minimal help)

|Documentation
|1x
|0.2-0.3x (major speedup)
|===

Total project timeline compression: perhaps *30-40%*—meaningful but not an order of magnitude.

<<<

== Existing Work to Study

=== Systems and Their Key Insights

[cols="1,3",options="header"]
|===
|System |Key Insight for AETHEROS

|*seL4*
|Capability model done right. Formal verification of C implementation is possible. The gold standard for microkernel security.

|*Redox OS*
|Rust microkernel is viable. Unix-like design provides familiar ground. Shows what one dedicated developer can achieve.

|*Fuchsia/Zircon*
|Object-capability model at scale. Handles (not file descriptors) as the universal abstraction. Component-based architecture.

|*Hubris (Oxide Computer)*
|Rust RTOS for production embedded systems. Demonstrates Rust viability for safety-critical, real-time code.

|*Theseus*
|Rust OS with live evolution and novel state management. Shows how Rust's type system can enforce OS invariants.

|*Legion (Stanford)*
|Dataflow runtime for heterogeneous compute. The Realm runtime shows how to manage distributed heterogeneous memory.

|*Halide*
|Algorithm/schedule separation. The key insight for making heterogeneous compute programmable.

|*Regent*
|Implicit parallelism via Legion. Shows how high-level languages can target complex runtimes.
|===

=== Foundational Research

[cols="1,2",options="header"]
|===
|Area |Key Works

|*Capability Systems*
|Dennis & Van Horn (1966), EROS, seL4 proofs

|*Microkernel Design*
|L4 family, Mach critique, seL4

|*Formal Verification*
|CompCert, seL4, CertiKOS

|*Dataflow Execution*
|Dataflow architectures, Legion, TensorFlow graphs

|*Session Types*
|Honda (1993), Gay & Hole, Rust session types

|*Linear Types*
|Girard, Wadler, Rust ownership
|===

=== What to Absorb vs. What to Invent

[cols="1,1,1",options="header"]
|===
|Absorb (proven ideas) |Adapt (modify for context) |Invent (novel contributions)

|Capability model (seL4)
|Microkernel structure (L4 → quadripartite)
|Emotive kernel concept

|Session types
|Dataflow scheduling (Legion → user-centric)
|User intent inference model

|Memory safety (Rust)
|GPU integration (ROCm → native)
|Algorithm/schedule DSL for heterogeneous compute

|Formal methods (TLA+, Lean)
|Persistence model (checkpoint-based)
|Experience quality computation
|===

<<<

== Development Phases

=== Phase 1: Capability Algebra

*Deliverables:*

* Complete Lean 4 specification of capability model
* Proofs of no-forgery, no-amplification, revocation propagation
* TLA+ behavioral specification
* Model checking results

=== Phase 2: Resource Model

*Deliverables:*

* Memory domain type definitions
* Compute unit abstractions
* Channel session types
* Resource lifecycle proofs

=== Phase 3: Kernel Specifications

*Deliverables:*

* Complete specification of all four kernels in Lean 4
* TLA+ concurrent behavior specifications
* Inter-kernel protocol verification
* Invariant proofs

=== Phase 4: Prototype Implementation

*Deliverables:*

* Minimal Rust microkernel (Governance + Physical)
* Capability-based IPC working on QEMU
* Basic memory management
* Timer and interrupt handling

=== Phase 5: Emotive Kernel Implementation

*Deliverables:*

* Intent inference engine
* Experience quality monitoring
* Priority computation
* User presence detection

=== Phase 6: Cognitive Kernel Implementation

*Deliverables:*

* Compute graph scheduler
* Heterogeneous placement engine
* GPU/NPU integration via Physical kernel
* Deadline-aware scheduling

=== Phase 7: Hardware Integration

*Deliverables:*

* Bare-metal boot on Threadripper PRO
* Native GPU driver (RDNA)
* NPU driver (XDNA)
* Full NUMA-aware memory management

=== Phase 8: Application Runtime

*Deliverables:*

* Capability-based application model
* WASM runtime for portable applications
* Native Rust application support
* Developer SDK

<<<

== Appendix A: Glossary

[cols="1,3",options="header"]
|===
|Term |Definition

|*Capability*
|Unforgeable token encoding authority to act on a resource

|*Channel*
|Typed, capability-protected conduit for inter-kernel communication

|*Checkpoint*
|Consistent snapshot of system state for persistence/recovery

|*Compute Graph*
|Dataflow representation of computation with explicit dependencies

|*Domain*
|Isolated state container; unit of protection

|*Epoch*
|Monotonic counter tracking system state versions

|*Invariant*
|Property that must hold across all state transitions

|*MA (間)*
|Japanese aesthetic principle of meaningful negative space

|*Provenance*
|Capability lineage for revocation tracking

|*Resource*
|Any entity that can be owned, accessed, or consumed

|*Rights*
|Permissions encoded in a capability (read, write, execute, grant, revoke)

|*Session Type*
|Type encoding valid sequences of channel operations

|*Transition*
|Function mapping current state + event to new state
|===

<<<

== Appendix B: Reference Materials

=== Systems to Study

[cols="1,3",options="header"]
|===
|System |Key Insight

|*seL4*
|Capability model done right; formal verification achieved

|*Redox OS*
|Rust microkernel; Unix-like but instructive

|*Fuchsia/Zircon*
|Object-capability model; handles not file descriptors

|*Hubris (Oxide)*
|Rust RTOS for embedded; principled design

|*Theseus*
|Rust OS with live evolution; novel state management

|*Legion (Stanford)*
|Dataflow runtime for heterogeneous compute

|*Halide*
|Algorithm/schedule separation for compute kernels
|===

=== Foundational Papers

* Shapiro, J. "EROS: A Fast Capability System"
* Klein, G. et al. "seL4: Formal Verification of an OS Kernel"
* Lamport, L. "The Temporal Logic of Actions"
* Honda, K. "Session Types for Object-Oriented Languages"
* Gay, S. & Hole, M. "Subtyping for Session Types"
* Wadler, P. "Linear Types Can Change the World"

<<<

== Appendix C: AMD Platform Specifications

=== Target Hardware: Threadripper PRO 9995WX

[cols="1,2",options="header"]
|===
|Specification |Value

|*CPU Cores*
|96 cores / 192 threads (Zen 5)

|*Memory Channels*
|12-channel DDR5

|*Maximum RAM*
|3TB (registered ECC)

|*Memory Bandwidth*
|~460 GB/s

|*PCIe*
|PCIe 5.0, 128 lanes

|*TDP*
|350W (configurable)
|===

=== GPU: RDNA Architecture

[cols="1,2",options="header"]
|===
|Characteristic |Implication for AETHEROS

|*Compute Units*
|Variable by SKU; managed by Physical kernel

|*Memory*
|Device-local VRAM; explicit coherence required

|*Scheduling*
|Hardware scheduler; non-deterministic timing

|*Programming*
|HIP/ROCm (C++); target for DSL compilation
|===

=== NPU: XDNA Architecture

[cols="1,2",options="header"]
|===
|Characteristic |Implication for AETHEROS

|*Tiles*
|AI Engine tiles for inference

|*Memory*
|Shared with CPU; DMA transfers

|*Programming*
|Proprietary SDK; abstracted by Cognitive kernel

|*Use Case*
|ML inference acceleration; pattern recognition for Emotive kernel
|===

<<<

== Appendix D: Document History

[cols="1,1,3",options="header"]
|===
|Version |Date |Changes

|0.1.0
|2025-01-01
|Initial specification draft from architectural discussions

|0.2.0
|2025-01-01
|Added: Language Assessment section with detailed comparison; GPU/NPU DSL problem analysis; Critical Risks and Mitigations; Bootstrap Strategy; Existing Work to Study; AMD Platform Specifications appendix

|0.3.0
|2025-01-01
|Added: Key Innovations section with detailed descriptions of Capabilities, Dataflow, Memory Domains, and Typed Channels; System Layers diagram showing User Space through Hardware Abstraction; AI-Assisted Development Model section covering Claude Code collaboration topology, capabilities, limitations, and workflow recommendations; Incorporated all RWProject architectural discussions
|===

== Colophon

This document was produced through Socratic dialogue, applying principles of MA to achieve conceptual clarity through careful removal of the inessential.

[quote, Antoine de Saint-Exupéry]
____
Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.
____

// End of specification
